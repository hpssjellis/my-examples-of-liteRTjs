<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0" />
    <title>LiteRT.js Depth Estimation Demo</title>
    
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            overflow: hidden;
            background-color: #000;
        }
        
        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: 1;
            opacity: 0.5;
        }

        #webcam {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: 0;
        }

        #controls {
            position: absolute;
            top: 10px;
            left: 10px;
            z-index: 2;
            padding: 10px;
            background: rgba(255, 255, 255, 0.8);
            border-radius: 5px;
            display: flex;
            gap: 10px;
            font-family: sans-serif;
        }
    </style>

    <script type="module">
        import * as LiteRT from 'https://cdn.jsdelivr.net/npm/@litertjs/core@0.2.1/+esm';
        import * as LiteRTInterop from 'https://cdn.jsdelivr.net/npm/@litertjs/tfjs-interop/+esm';
        import 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js';
        import 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgpu/dist/tf-backend-webgpu.js';
        
        // --- Global Variables (my-prefixed) ---
        const myModelUrl = 'https://huggingface.co/qualcomm/Depth-Anything-V2/resolve/main/Depth-Anything-V2_float.tflite';
        let myModel = undefined;
        let myIsPredicting = false; // Flag to prevent multiple prediction loops
        
        const myVideoElement = document.getElementById('webcam');
        const myOverlayCanvas = document.getElementById('overlay');
        const myLoadButton = document.getElementById('loadModelButton');
        const myCameraSelect = document.getElementById('cameraSelect');

        // --- Core Functions ---

        /**
         * Populates the camera selection dropdown with available video input devices.
         */
        async function myGetCameras() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
                console.warn('enumerateDevices() not supported.');
                return;
            }

            try {
                const myDevices = await navigator.mediaDevices.enumerateDevices();
                // Filter for video input devices
                const myVideoDevices = myDevices.filter(myDevice => myDevice.kind === 'videoinput');
                
                myCameraSelect.innerHTML = ''; // Clear existing options
                
                if (myVideoDevices.length === 0) {
                    console.error('No video input devices found.');
                    myCameraSelect.innerHTML = '<option>No Camera Found</option>';
                    myCameraSelect.disabled = true;
                    return;
                }

                myVideoDevices.forEach((myDevice, myIndex) => {
                    const myOption = document.createElement('option');
                    myOption.value = myDevice.deviceId;
                    // Provide a default label if none is available (e.g., initially)
                    myOption.text = myDevice.label || `Camera ${myIndex + 1}`; 
                    myCameraSelect.appendChild(myOption);
                });

                myCameraSelect.disabled = false;
                
            } catch (e) {
                console.error('Error listing devices:', e);
            }
        }
        
        /**
         * Enables the webcam using the currently selected device ID.
         * @param {string} myDeviceId - The ID of the camera to use.
         */
        async function myEnableWebcam(myDeviceId) {
            // Stop existing stream if running
            if (myVideoElement.srcObject) {
                myVideoElement.srcObject.getTracks().forEach(track => track.stop());
            }

            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                console.error('Browser API navigator.mediaDevices.getUserMedia not available');
                return;
            }
            
            const myVideoConfig = {
                'audio': false,
                'video': {
                    deviceId: myDeviceId ? { exact: myDeviceId } : undefined, // Use specific device ID if provided
                    width: 640,
                    height: 480
                }
            };
            
            try {
                const myStream = await navigator.mediaDevices.getUserMedia(myVideoConfig);
                myVideoElement.srcObject = myStream;
                await new Promise(resolve => myVideoElement.onloadedmetadata = resolve); // Wait for metadata to load
                console.log('Video stream started successfully.');
            } catch (e) {
                console.error('Error enabling webcam:', e);
                // Fallback or detailed error handling
            }
        }

        /**
         * Loads the LiteRT environment and the Depth Estimation model.
         */
        async function myLoadModel() {
            if (myModel !== undefined || myIsPredicting) return; // Prevent double loading
            
            myLoadButton.textContent = 'Loading...';
            myLoadButton.disabled = true;
            myCameraSelect.disabled = true;

            try {
                // 1. Start Webcam with selected device
                await myEnableWebcam(myCameraSelect.value);

                // 2. Load Model & Backend
                console.log('Setting up WebGPU backend...');
                await tf.setBackend('webgpu');
                await LiteRT.loadLiteRt('https://assets.codepen.io/48236/');
                const myTfBackend = tf.backend();
                LiteRT.setWebGpuDevice(myTfBackend.device);
                
                console.log('Loading and compiling model...');
                myModel = await LiteRT.loadAndCompile(myModelUrl, {
                    accelerator: 'webgpu',
                });
                
                // 3. Start Prediction Loop
                console.log('Model loaded. Starting prediction.');
                myLoadButton.textContent = 'Model Loaded (Running)';
                myIsPredicting = true;
                myPredict();
                
            } catch (e) {
                console.error('Error during model loading or setup:', e);
                myLoadButton.textContent = 'Error Loading Model';
            }
        }
        
        /**
         * Main prediction loop using requestAnimationFrame.
         */
       async function myPredict() {
    if (myModel === undefined || !myIsPredicting) return;

    // Use tf.tidy to ensure Tensors are cleaned up correctly unless marked for saving
    tf.tidy(() => {
        const myInputTensor = tf.browser.fromPixels(myVideoElement)
            .resizeBilinear([518, 518])
            .div(255.0)
            .expandDims();
        
        const myResults = LiteRTInterop.runWithTfjsTensors(myModel, myInputTensor);
        const myOutputTensor = myResults[0];
        
        // Normalize output to 0-1 for display
        const myMin = myOutputTensor.min();
        const myMax = myOutputTensor.max();
        const myNormalized = myOutputTensor.sub(myMin).div(myMax.sub(myMin)).squeeze();
        
        // Create RGB tensor for gradient visualization (Blue=Far, Green=Close)
        const myZeros = tf.zerosLike(myNormalized);
        const myBlueChannel = tf.sub(1, myNormalized);
        const myRgbTensor = tf.stack([myZeros, myNormalized, myBlueChannel], 2);
        
        
        // Calculate crop to emulate object-fit: cover
        const videoRatio = myVideoElement.videoWidth / myVideoElement.videoHeight;
        const windowRatio = window.innerWidth / window.innerHeight;
        const scale = videoRatio / windowRatio;
        
        // Apply scaling via inline CSS
        if (scale > 1) {
            myOverlayCanvas.style.scale = `${scale} 1`;
        } else {
            myOverlayCanvas.style.scale = `1 ${1 / scale}`;
        }
        
        // --- THIS IS THE MODIFIED LINE ---
        tf.browser.draw(myRgbTensor.clipByValue(0, 1), myOverlayCanvas, { flipHorizontal: true });
        
        // Note: Tensors in tidy() are disposed here, except those passed out or explicitly saved.
        // The results from LiteRTInterop are disposed manually below as they are outside tidy.
        for (const output of myResults) {
            output.dispose();
        }
    });
    
    // Wait for GPU work to finish submitting before requesting the next frame
    await tf.backend().queue.onSubmittedWorkDone();
    
    requestAnimationFrame(myPredict);
}
        /**
         * Handles camera changes, stopping the current prediction and restarting the stream.
         */
        async function myCameraChangeHandler() {
            if (myIsPredicting) {
                // If model is running, restart the stream with the new camera
                await myEnableWebcam(myCameraSelect.value);
            } else {
                // If not running, just switch the camera to show the feed immediately
                await myEnableWebcam(myCameraSelect.value);
            }
        }

        // --- Initialization and Event Listeners (Static Links) ---
        
        myLoadButton.onclick = myLoadModel;
        myCameraSelect.onchange = myCameraChangeHandler;

        // Populate the camera select box on script load
        myGetCameras();

        // Initially try to enable the webcam so the user can see the feed before loading the heavy model
        myEnableWebcam();
    </script>
</head>
<body>
    <div id="controls">
        <label for="cameraSelect">Camera:</label>
        <select id="cameraSelect">
            <option value="">Loading Cameras...</option>
        </select>
        <button id="loadModelButton">Load Model & Start</button>
    </div>

    <video id="webcam" autoplay playsinline></video>
    <canvas id="output"></canvas> 
    <canvas id="overlay"></canvas>
    
    <section id="demos" style="display: none;">
        <h1>LiteRT.js Depth Estimation Demo</h1>
        <p>This demo performs real-time depth estimation.</p>
    </section>
</body>
</html>
