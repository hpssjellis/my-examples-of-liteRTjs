<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>myTFLiteClassification</title>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.2.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite@0.0.1-alpha.9/dist/tf-tflite.min.js"></script>
</head>
<body>

    <script>
        // =================================================================
        // üöÄ USER-CONFIGURABLE MODEL SETTINGS (Classification Example)
        // =================================================================
        const myModelConfig = {
            // NOTE: This URL is now a PLACEHOLDER for a 240x240 Classification model. 
            // In a real project, you would replace this with the URL to your Edge Impulse 
            // classification TFLite file.
            myModelFileName: 'https://hpssjellis.github.io/my-examples-of-edge-impulse/public/tflite/classification-240.tflite', 

            myInputResolution: 240, 
            myInputChannels: 3, 

            // These are the classes your classification model predicts
            myClassLabels: ['Class_One', 'Class_Two', 'Unknown_Background'], 
        };
        // =================================================================
        // ‚öôÔ∏è INTERNAL VARIABLES (DO NOT EDIT)
        // =================================================================
        let myTfLiteModel = null;
        let myIsWebcamReady = false;
        let myCanvasElement = null;
        let myVideoElement = null;
        let myContext = null;
        let myStatusElement = null;
        let myAnimationFrameId = null;
        let myFileInput = null; // Global reference for file input for Method A

        // Derived variables for quick access
        const myInputSize = myModelConfig.myInputResolution;
        
        // =================================================================
        // üè† HTML SETUP (Inline CSS and Elements)
        // =================================================================
        function myCreateDOM() {
            // Create minimal CSS for structure, using inline styles for simplicity
            document.head.innerHTML += `
                <style>
                    body { font-family: Arial, sans-serif; display: flex; flex-direction: column; align-items: center; margin: 20px; background-color: #f4f4f9; }
                    #myControls { margin-bottom: 20px; padding: 15px; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1); }
                    #myCanvas { border: 2px solid #333; border-radius: 8px; margin-top: 10px; background-color: #333; }
                    #myVideo { display: none; } /* Hidden video to feed the canvas */
                    .myButton { background-color: #0d9488; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 16px; transition: background-color 0.3s; }
                    .myButton:hover { background-color: #047876; }
                    .myStatus { margin-top: 10px; font-weight: bold; color: #047876; text-align: center; font-size: 1.2em;}
                    .myLabel { display: block; margin-top: 5px; }
                </style>
            `;

            // Controls Div
            const myControlsDiv = document.createElement('div');
            myControlsDiv.id = 'myControls';
            
            // --- ADDED for Method A (From Computer) ---
            const myFileInputLabel = document.createElement('label');
            myFileInputLabel.className = 'myLabel';
            myFileInputLabel.textContent = '1. Select TFLite file (For Method A):';
            myFileInputLabel.htmlFor = 'myFileInput';
            myControlsDiv.appendChild(myFileInputLabel);
            
            myFileInput = document.createElement('input'); // Assign to global variable
            myFileInput.type = 'file';
            myFileInput.id = 'myFileInput';
            myFileInput.accept = '.tflite';
            myFileInput.style.marginBottom = '15px';
            myControlsDiv.appendChild(myFileInput);
            // ----------------------------------------
            
            const myStartButton = document.createElement('button');
            myStartButton.className = 'myButton';
            myStartButton.id = 'myStartButton';
            myStartButton.textContent = `2. Load Model (Remote URL - Method B) and Start Webcam`; // Updated button text
            myStartButton.onclick = myStartDetection; // Static link to function name
            myControlsDiv.appendChild(myStartButton);

            myStatusElement = document.createElement('p');
            myStatusElement.className = 'myStatus';
            myStatusElement.id = 'myStatusMessage';
            myStatusElement.textContent = 'Click the button to begin...';
            myControlsDiv.appendChild(myStatusElement);
            document.body.appendChild(myControlsDiv);

            // Video Element
            myVideoElement = document.createElement('video');
            myVideoElement.id = 'myVideo';
            myVideoElement.setAttribute('playsinline', '');
            myVideoElement.setAttribute('autoplay', '');
            document.body.appendChild(myVideoElement);

            // Canvas Element
            myCanvasElement = document.createElement('canvas');
            myCanvasElement.id = 'myCanvas';
            // Use the configured resolution for the canvas size
            myCanvasElement.width = myInputSize;
            myCanvasElement.height = myInputSize; 
            document.body.appendChild(myCanvasElement);

            myContext = myCanvasElement.getContext('2d');
        }
        
        // =================================================================
        // üíª APPLICATION FLOW
        // =================================================================
        
        window.onload = myCreateDOM; // Create everything on load

        /**
         * @function myStartDetection
         * Loads the model and starts the webcam.
         */
        async function myStartDetection() {
            const myStartButton = document.getElementById('myStartButton');
            myStartButton.disabled = true;
            myStatusElement.textContent = `Loading model... Please wait.`;
            
            myStopInferenceLoop(); // Stop any previous loop

            try {
                
                // =======================================================================================
                // --- A. FROM THE USER'S COMPUTER (via file input) ---
                // UNCOMMENT BELOW TO USE METHOD A (requires the user to select a file using the file input above)
                /* const mySelectedFile = myFileInput.files[0];

                if (mySelectedFile) {
                    myStatusElement.textContent = 'Status: Loading model using File Input (A)...';
                    // tf.tflite.loadTFLiteModel can directly handle a File object
                    myTfLiteModel = await tflite.loadTFLiteModel(mySelectedFile);
                } else {
                    myStatusElement.textContent = 'Status: Please select a .tflite file first to test Method A.';
                    myStartButton.disabled = false;
                    return;
                }
                */
                // =======================================================================================


                // =======================================================================================
                // --- C. FROM THE SAME FOLDER (Relative Path) ---
                // UNCOMMENT BELOW TO USE METHOD C (requires the model file to be local to the HTML)
                /*
                const myLocalFileName = 'classification-240.tflite'; 
                const myLocalModelPath = `./${myLocalFileName}`; 

                myStatusElement.textContent = `Status: Loading model using Local Path (C):\nPath: ${myLocalModelPath}`;
                myTfLiteModel = await tflite.loadTFLiteModel(myLocalModelPath);
                // Note: This will fail if the file is not found.
                */
                // =======================================================================================


                // =======================================================================================
                // --- B. FROM A REMOTE URL (e.g., GitHub, CDN) - ACTIVE METHOD ---
                // This is the active method, using the URL defined in myModelConfig.myModelFileName
                
                myStatusElement.textContent = `Status: Loading model using Remote URL (B):\nPath: ${myModelConfig.myModelFileName}`;
                // The browser will attempt to fetch this URL.
                myTfLiteModel = await tflite.loadTFLiteModel(myModelConfig.myModelFileName);
                // =======================================================================================


                myStatusElement.textContent = 'Model loaded successfully! Starting webcam...';
                console.log('TFLite Model Loaded:', myModelConfig.myModelFileName);

                // Start the webcam
                await mySetupWebcam();

            } catch (myError) {
                // If it fails due to network issues (like 404) or CORS, the error message here will reflect it.
                myStatusElement.textContent = `Failed to load model: ${myError.message}. Check the console for details (F12).`;
                console.error('Model loading error:', myError);
                document.getElementById('myStartButton').disabled = false;
            }
        }

        /**
         * @function mySetupWebcam
         * Initializes the webcam stream.
         */
        async function mySetupWebcam() {
            if (myIsWebcamReady) return;

            try {
                const myStream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: myInputSize,
                        height: myInputSize,
                        facingMode: 'user'
                    },
                    audio: false
                });

                myVideoElement.srcObject = myStream;
                await new Promise(myResolve => myVideoElement.onloadedmetadata = myResolve);

                myVideoElement.play();
                myIsWebcamReady = true;
                myStatusElement.textContent = 'Webcam active. Running inference...';

                myRunInferenceLoop();

            } catch (myError) {
                myStatusElement.textContent = `Error accessing webcam: ${myError.message}.`;
                console.error('Webcam access error:', myError);
                document.getElementById('myStartButton').disabled = false;
            }
        }

        /**
         * @function myRunInferenceLoop
         * The main loop for frame capture and model inference.
         */
        function myRunInferenceLoop() {
            tf.tidy(() => {
                if (!myTfLiteModel || !myIsWebcamReady) {
                    return;
                }

                // 1. Capture and Preprocess Frame
                myContext.drawImage(myVideoElement, 0, 0, myInputSize, myInputSize);
                let myInputTensor = tf.browser.fromPixels(myCanvasElement, myModelConfig.myInputChannels);

                // Normalize and add batch dimension [1, H, W, C]
                let myNormalizedTensor = myInputTensor
                    .resizeBilinear([myInputSize, myInputSize])
                    .cast('float32')
                    .div(255.0)
                    .expandDims(0); 

                // 2. Run Inference
                const myOutputTensor = myTfLiteModel.predict(myNormalizedTensor);

                // 3. Post-processing (Classification-specific)
                myPostProcessClassification(myOutputTensor);
            }); 

            myAnimationFrameId = requestAnimationFrame(myRunInferenceLoop);
        }
        
        /**
         * @function myPostProcessClassification
         * Interprets the single output vector for classification.
         * The model output is a 1D array of probabilities for each class.
         * We update the status element, not the canvas.
         */
        function myPostProcessClassification(myOutputTensor) {
            // Get the data from the output tensor (a single array of class probabilities)
            const myProbabilities = myOutputTensor.dataSync();
            
            let myMaxProbability = 0;
            let myMaxIndex = -1;

            // Find the index of the highest probability
            for (let i = 0; i < myProbabilities.length; i++) {
                if (myProbabilities[i] > myMaxProbability) {
                    myMaxProbability = myProbabilities[i];
                    myMaxIndex = i;
                }
            }

            // Determine the predicted label and format the confidence
            const myPredictedLabel = myModelConfig.myClassLabels[myMaxIndex] || 'Unknown';
            const myConfidence = (myMaxProbability * 100).toFixed(1); // One decimal place

            // 4. Update status display
            myStatusElement.textContent = `Prediction: ${myPredictedLabel} (${myConfidence}%)`;

            // 5. Draw the video frame on the canvas continuously
            myContext.drawImage(myVideoElement, 0, 0, myInputSize, myInputSize);
        }

        /**
         * @function myStopInferenceLoop
         * Stops the continuous frame request loop.
         */
        function myStopInferenceLoop() {
            if (myAnimationFrameId) {
                cancelAnimationFrame(myAnimationFrameId);
                myAnimationFrameId = null;
            }
        }
    </script>
</body>
</html>
