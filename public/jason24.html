<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0" />
    <title>LiteRT.js Model Debug Logger</title>
    
    <script type="module">
        // Import all necessary modules
        import * as LiteRT from 'https://cdn.jsdelivr.net/npm/@litertjs/core@0.2.1/+esm';
        import * as LiteRTInterop from 'https://cdn.jsdelivr.net/npm/@litertjs/tfjs-interop/+esm';
        import 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js';
        import 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgpu/dist/tf-backend-webgpu.js';
        
        // --- Model Configuration Data ---
        const myDepthModels = [
            { 
                myName: "Depth-Anything V2 Large", 
                myUrl: 'https://huggingface.co/qualcomm/Depth-Anything-V2/resolve/main/Depth-Anything-V2_float.tflite'
            },
            { 
                myName: "Quantized Mobilenet V1 224 (Example)", 
                myUrl: 'https://storage.googleapis.com/tfjs-models/demos/mobilenet/model_224/quantized/uint8/model.json' 
            },
            { 
                myName: "MobileNet-Depth 256x256", 
                myUrl: 'https://huggingface.co/qualcomm/MobileNet-Depth-Estimation/resolve/main/MobileNet-Depth-Estimation_float.tflite'
            },
            {
                myName: "MiDaS v2.1 Small",
                myUrl: 'https://huggingface.co/PINTO0309/MiDaS.tflite/resolve/main/midas_v2_small_256x256_float32.tflite'
            },
            {
                myName: "Fomo",
                myUrl: 'https://hpssjellis.github.io/my-examples-of-liteRTjs/public/tflite/ei-ei-andrew-3d-printed-symbol-fomo-object-detection-tensorflow-lite-float32-model.5.tflite'
            },
            {
                myName: "fomo pen",
                myUrl: 'https://hpssjellis.github.io/my-examples-of-liteRTjs/public/tflite/ei-ei-fomo-pen-object-detection-tensorflow-lite-float32-model.5.tflite'
            },
            {
                myName: "brush",
                myUrl: 'https://hpssjellis.github.io/my-examples-of-liteRTjs/public/tflite/ei-ei-jeremy-0unknown-1brush-2paint-v01-transfer-learning-tensorflow-lite-float32-model.5.tflite'
            },
            {
                myName: "96 mnist",
                myUrl: 'https://hpssjellis.github.io/my-examples-of-liteRTjs/public/tflite/ei-ei-v1-5-0-minst-96x96-f180-object-detection-tensorflow-lite-float32-model.5.tflite'
            },
            {
                myName: "Jer Cups",
                myUrl: 'https://hpssjellis.github.io/my-examples-of-liteRTjs/public/tflite/ei-ei-v8-1-1-jeremy-rc-car-1red-2white-cup-fomo-96x96-object-detection-tensorflow-lite-float32-model.5.tflite'
            },
            {
                myName: "anomoly",
                myUrl: 'https://hpssjellis.github.io/my-examples-of-liteRTjs/public/tflite/ei-ei-v1-motion-anamoly-still-classifier-tensorflow-lite-float32-model.15.tflite'
            },
            {
                myName: "pen",
                myUrl: 'https://hpssjellis.github.io/my-examples-of-liteRTjs/public/tflite/ei-ei-v1-fomo-pen-jeremy-object-detection-tensorflow-lite-float32-model.5.tflite'
            }
        ];

        // --- Global Variables (my-prefixed) ---
        let myModel = undefined;
        let myIsPredicting = false;
        let myTimerIntervalId = null; 
        let myInitialPredictionStartTime = 0; 
        let myCurrentInputShape = 0;
        let myModelName = ''; 
        let myInputChannels = 3; 
        let myInputDtype = 'float32'; 
        let myOutputShapeString = 'N/A';
        let myLoadedModelUrl = ''; 
        let myLiteRTInitializedPromise = null; 
        let myFrameCount = 0;

        // --- DOM Element References ---
        const myVideoElement = document.getElementById('webcam');
        const myOverlayCanvas = document.getElementById('overlay');
        const myLoadButton = document.getElementById('loadModelButton');
        const myResetButton = document.getElementById('myResetButton'); 
        const myCameraSelect = document.getElementById('cameraSelect');
        const myModelSelect = document.getElementById('modelSelect'); 
        const myModelUrlInput = document.getElementById('myModelUrlInput'); 
        const myLoadStatusSpan = document.getElementById('myLoadStatus');
        const myAnalysisStatusSpan = document.getElementById('myAnalysisStatus');
        const myInputShapeSpan = document.getElementById('myInputShapeStatus');
        const myInputDtypeSpan = document.getElementById('myInputDtypeStatus'); 
        const myOutputDetailsSpan = document.getElementById('myOutputDetailsStatus'); 

        // --- Timer Functions ---
        function myStartLoadTimer() {
            let myStartTime = performance.now();
            myLoadStatusSpan.textContent = '0.0s';
            myTimerIntervalId = setInterval(() => {
                let myElapsedTime = performance.now() - myStartTime;
                myLoadStatusSpan.textContent = `${(myElapsedTime / 1000).toFixed(1)}s`;
            }, 100);
        }

        function myStopLoadTimer(myFinalMessage) {
            if (myTimerIntervalId !== null) {
                clearInterval(myTimerIntervalId);
                myTimerIntervalId = null;
            }
            myLoadStatusSpan.textContent = myFinalMessage;
        }
        
        // --- Utility Functions ---
        function myStopPredictionAndReset() {
            if (myIsPredicting) {
                myIsPredicting = false;
                console.log('üõë Prediction stopped');
            }
            myLoadButton.textContent = 'Load Model & Start';
            myLoadButton.disabled = false;
            myCameraSelect.disabled = false;
            myAnalysisStatusSpan.textContent = 'N/A';
            myInitialPredictionStartTime = 0;
            myFrameCount = 0;
        }

        function myFullReset() {
            console.log('üîÑ Full reset initiated');
            myStopPredictionAndReset();
            
            if (myModel) {
                try {
                    myModel.delete();
                    console.log('‚úÖ Model disposed successfully');
                } catch(e) {
                     console.warn("‚ö†Ô∏è Could not dispose of model gracefully:", e);
                }
                myModel = undefined;
            }
            myLoadedModelUrl = '';
            
            myStopLoadTimer('Ready');
            myAnalysisStatusSpan.textContent = 'N/A';
            myInputShapeSpan.textContent = 'N/A';
            myInputDtypeSpan.textContent = 'N/A';
            myOutputDetailsSpan.textContent = 'N/A';

            myModelUrlInput.value = ''; 
            myModelSelect.selectedIndex = -1; 
            
            myLoadButton.disabled = true; 
            myLoadButton.textContent = 'Enter Model URL to Load';
            myModelSelect.disabled = false;
            myCameraSelect.disabled = false;
        }

        function myPopulateModelSelect() {
            myModelSelect.innerHTML = ''; 
            myDepthModels.forEach((myModel, myIndex) => {
                const myOption = document.createElement('option');
                myOption.value = myModel.myUrl;
                myOption.text = myModel.myName;
                myModelSelect.appendChild(myOption);
            });
            
            if (myDepthModels.length > 0) {
                 myModelUrlInput.value = myDepthModels[0].myUrl;
            }
            myPreLoadModelMetadata();
        }

        async function myInitializeLiteRT() {
            if (myLiteRTInitializedPromise) {
                return myLiteRTInitializedPromise;
            }

            myLiteRTInitializedPromise = (async () => {
                console.log('üöÄ Initializing LiteRT...');
                try {
                    await tf.setBackend('webgpu');
                    console.log('‚úÖ TensorFlow.js backend: WebGPU');
                } catch (e) {
                    console.log('‚ö†Ô∏è WebGPU not available, trying WebGL...');
                    try {
                        await tf.setBackend('webgl');
                        console.log('‚úÖ TensorFlow.js backend: WebGL');
                    } catch (e2) {
                        await tf.setBackend('cpu');
                        console.log('‚ö†Ô∏è Using CPU backend (slower)');
                    }
                }
                
                await LiteRT.loadLiteRt('https://cdn.jsdelivr.net/npm/@litertjs/core@0.2.1/wasm/');
                const myTfBackend = tf.backend();
                LiteRT.setWebGpuDevice(myTfBackend.device); 
                console.log('‚úÖ LiteRT initialized successfully');
            })();

            return myLiteRTInitializedPromise;
        }

        // --- Webcam Functions ---
        async function myEnableWebcam(myDeviceId) {
            if (myVideoElement.srcObject) {
                myVideoElement.srcObject.getTracks().forEach(track => track.stop());
                myVideoElement.srcObject = null;
            }
            
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                console.error('‚ùå Webcam not supported');
                return;
            }
            
            const myVideoConfig = {'audio': false, 'video': {deviceId: myDeviceId ? { exact: myDeviceId } : undefined, width: 640, height: 480}};
            
            try {
                const myStream = await navigator.mediaDevices.getUserMedia(myVideoConfig);
                myVideoElement.srcObject = myStream;
                await new Promise(resolve => myVideoElement.onloadedmetadata = resolve);
                myVideoElement.play(); 
                console.log('üìπ Webcam enabled');
            } catch (e) {
                console.error('‚ùå Error enabling webcam:', e);
            }
        }
        
        async function myGetCameras() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
                return;
            }

            try {
                const myTempStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                myTempStream.getTracks().forEach(track => track.stop());

                const myDevices = await navigator.mediaDevices.enumerateDevices();
                const myVideoDevices = myDevices.filter(myDevice => myDevice.kind === 'videoinput');
                
                myCameraSelect.innerHTML = '';
                
                if (myVideoDevices.length === 0) {
                    myCameraSelect.innerHTML = '<option>No Camera Found</option>';
                    myCameraSelect.disabled = true;
                    return;
                }

                myVideoDevices.forEach((myDevice, myIndex) => {
                    const myOption = document.createElement('option');
                    myOption.value = myDevice.deviceId;
                    myOption.text = myDevice.label || `Camera ${myIndex + 1}`; 
                    myCameraSelect.appendChild(myOption);
                });

                myCameraSelect.disabled = false;
                console.log(`üìπ Found ${myVideoDevices.length} camera(s)`);
                
            } catch (e) {
                console.error('‚ùå Error listing devices or getting stream:', e);
                myCameraSelect.innerHTML = '<option>Access Denied or Error</option>';
            }
        }

        async function myPreLoadModelMetadata() {
            myStopPredictionAndReset();

            const myModelUrl = myModelUrlInput.value.trim();
            if (!myModelUrl) {
                myStopLoadTimer('Enter Model URL');
                myLoadButton.disabled = true; 
                myLoadButton.textContent = 'Enter Model URL to Load';
                return;
            }

            await myInitializeLiteRT(); 

            if (myLoadedModelUrl === myModelUrl) {
                myStopLoadTimer('Already Loaded');
                myLoadButton.disabled = false;
                myLoadButton.textContent = 'Load Model & Start';
                console.log('‚ÑπÔ∏è Model already loaded');
                return;
            }
            
            if (myModel) {
                try {
                    myModel.delete();
                } catch(e) {
                     console.warn("‚ö†Ô∏è Could not dispose of previous model gracefully:", e);
                }
                myModel = undefined;
            }
            myLoadedModelUrl = ''; 

            myLoadButton.textContent = 'Loading...';
            myLoadButton.disabled = true;
            myLoadStatusSpan.textContent = 'Downloading...';
            myInputShapeSpan.textContent = '...';
            myInputDtypeSpan.textContent = '...'; 
            myOutputDetailsSpan.textContent = '...'; 

            try {
                console.log('üì• Loading model from:', myModelUrl);
                myStartLoadTimer();
                
                myModel = await LiteRT.loadAndCompile(myModelUrl, {
                    accelerator: 'webgpu',
                });
                myLoadedModelUrl = myModelUrl; 
                console.log('‚úÖ Model loaded successfully');

                const myInputDetails = myModel.getInputDetails();
                console.log('üìä INPUT DETAILS:', JSON.stringify(myInputDetails, null, 2));
                
                if (myInputDetails.length > 0) {
                    console.log(`   Number of inputs: ${myInputDetails.length}`);
                    myInputDetails.forEach((input, idx) => {
                        console.log(`   Input ${idx}:`, {
                            name: input.name,
                            shape: input.shape,
                            dtype: input.dtype,
                            quantization: input.quantization
                        });
                    });

                    if (myInputDetails[0].shape.length >= 3) {
                        myCurrentInputShape = myInputDetails[0].shape[1]; 
                        myInputChannels = myInputDetails[0].shape[3] || 1; 
                        myInputDtype = myInputDetails[0].dtype || 'float32'; 

                        myInputShapeSpan.textContent = `${myCurrentInputShape}x${myCurrentInputShape} (${myInputChannels} Ch)`;
                        myInputDtypeSpan.textContent = myInputDtype;
                        
                        console.log(`‚úÖ Using input shape: ${myCurrentInputShape}x${myCurrentInputShape}, channels: ${myInputChannels}, dtype: ${myInputDtype}`);
                    } else {
                        throw new Error("Could not determine model input shape from metadata.");
                    }
                } else {
                    throw new Error("No input details found.");
                }

                const myOutputDetails = myModel.getOutputDetails();
                console.log('üìä OUTPUT DETAILS:', JSON.stringify(myOutputDetails, null, 2));
                
                if (myOutputDetails.length > 0) {
                    console.log(`   Number of outputs: ${myOutputDetails.length}`);
                    myOutputDetails.forEach((output, idx) => {
                        console.log(`   Output ${idx}:`, {
                            name: output.name,
                            shape: output.shape,
                            dtype: output.dtype,
                            quantization: output.quantization
                        });
                    });

                    const myOutputShape = myOutputDetails[0].shape;
                    const myOutputShapeString = myOutputShape.join('x');
                    const myLabelsCount = myOutputShape.length > 1 ? myOutputShape[myOutputShape.length - 1] : 1; 

                    myOutputDetailsSpan.textContent = `${myOutputShapeString} (${myLabelsCount} Output)`;
                } else {
                    myOutputDetailsSpan.textContent = 'N/A';
                }
                
                myStopLoadTimer(`Ready: ${myLoadStatusSpan.textContent}`);
                myLoadButton.textContent = 'Load Model & Start';
                myLoadButton.disabled = false; 
                
            } catch (e) {
                myStopLoadTimer('Error');
                console.error('‚ùå Error during model loading or setup:', e);
                myLoadButton.textContent = 'Error Loading Model';
                myLoadedModelUrl = ''; 
            }
        }
        
        async function myLoadModel() {
            if (myIsPredicting || myLoadButton.disabled || !myModel) return; 

            await myEnableWebcam(myCameraSelect.value);

            myLoadButton.textContent = 'Compiling...';
            myLoadButton.disabled = true; 
            myModelSelect.disabled = true; 
            myCameraSelect.disabled = true;
            myAnalysisStatusSpan.textContent = `Compiling...`;
            myInitialPredictionStartTime = performance.now(); 

            myIsPredicting = true;
            myFrameCount = 0;
            console.log('‚ñ∂Ô∏è Starting prediction loop');
            myPredict();
        }
        
        async function myPredict() {
            if (myModel === undefined || !myIsPredicting || myCurrentInputShape === 0) {
                return;
            }

            if (myInitialPredictionStartTime > 0) {
                await tf.backend().queue.onSubmittedWorkDone();
                
                const myInitialDelay = performance.now() - myInitialPredictionStartTime;
                myAnalysisStatusSpan.textContent = `Delay: ${(myInitialDelay / 1000).toFixed(2)}s`;
                myLoadButton.textContent = 'Running';
                myLoadButton.disabled = true; 
                myInitialPredictionStartTime = 0; 
                console.log(`‚è±Ô∏è Initial compilation delay: ${(myInitialDelay / 1000).toFixed(2)}s`);
            }

            const shouldLogThisFrame = (myFrameCount % 30 === 0); // Log every 30 frames

            tf.tidy(() => {
                const myStartTime = performance.now(); 
                
                let myInputTensor = tf.browser.fromPixels(myVideoElement);
                
                if (shouldLogThisFrame) {
                    console.log(`\nüñºÔ∏è FRAME ${myFrameCount}:`);
                    console.log(`   Raw input shape: [${myInputTensor.shape}]`);
                    console.log(`   Raw input dtype: ${myInputTensor.dtype}`);
                }
                
                if (myInputChannels === 1) {
                    myInputTensor = myInputTensor.mean(2, true);
                    if (shouldLogThisFrame) console.log(`   Converted to grayscale`);
                }

                myInputTensor = myInputTensor.resizeBilinear([myCurrentInputShape, myCurrentInputShape]); 

                if (myInputDtype.startsWith('float')) {
                    myInputTensor = myInputTensor.div(255.0);
                    if (shouldLogThisFrame) console.log(`   Normalized to [0, 1] range`);
                } else if (myInputDtype.includes('uint8')) {
                    myInputTensor = myInputTensor.cast('int32'); // Cast to int32 first
                    if (shouldLogThisFrame) console.log(`   Cast to int32 for uint8 model`);
                } else if (myInputDtype.includes('int')) {
                    myInputTensor = myInputTensor.cast(myInputDtype); 
                    if (shouldLogThisFrame) console.log(`   Cast to ${myInputDtype}`);
                }
                
                myInputTensor = myInputTensor.expandDims(); 
                
                if (shouldLogThisFrame) {
                    console.log(`   Preprocessed input shape: [${myInputTensor.shape}]`);
                    console.log(`   Preprocessed input dtype: ${myInputTensor.dtype}`);
                    const minVal = myInputTensor.min().dataSync()[0];
                    const maxVal = myInputTensor.max().dataSync()[0];
                    console.log(`   Input value range: [${minVal.toFixed(4)}, ${maxVal.toFixed(4)}]`);
                }
                
                const myResults = LiteRTInterop.runWithTfjsTensors(myModel, myInputTensor);
                
                if (shouldLogThisFrame) {
                    console.log(`   Number of outputs: ${myResults.length}`);
                    myResults.forEach((output, idx) => {
                        const outMin = output.min().dataSync()[0];
                        const outMax = output.max().dataSync()[0];
                        const outMean = output.mean().dataSync()[0];
                        console.log(`   Output ${idx}:`, {
                            shape: `[${output.shape}]`,
                            dtype: output.dtype,
                            valueRange: `[${outMin.toFixed(4)}, ${outMax.toFixed(4)}]`,
                            mean: outMean.toFixed(4)
                        });
                    });
                }

                let myOutputTensor = myResults[0]; 
                
                myOutputTensor = myOutputTensor.squeeze();

                const myMin = myOutputTensor.min();
                const myMax = myOutputTensor.max();
                
                let myNormalized;
                if (myMax.dataSync()[0] === myMin.dataSync()[0]) {
                    myNormalized = tf.zerosLike(myOutputTensor); 
                } else {
                    myNormalized = myOutputTensor.sub(myMin).div(myMax.sub(myMin));
                }

                const myZeros = tf.zerosLike(myNormalized);
                const myBlueChannel = tf.sub(1, myNormalized);

                const myRgbTensor = tf.stack([myZeros, myNormalized, myBlueChannel], 2)
                                        .clipByValue(0, 1)
                                        .mul(255.0)
                                        .cast('int32'); 

                tf.browser.draw(myRgbTensor, myOverlayCanvas, { flipHorizontal: true });
                
                for (const output of myResults) {
                    output.dispose();
                }

                const myEndTime = performance.now();
                const myFrameTime = myEndTime - myStartTime;
                if (myInitialPredictionStartTime === 0) {
                    myAnalysisStatusSpan.textContent = `${myFrameTime.toFixed(0)}ms / ${(1000 / myFrameTime).toFixed(1)} FPS`;
                    if (shouldLogThisFrame) {
                        console.log(`   ‚è±Ô∏è Inference time: ${myFrameTime.toFixed(2)}ms (${(1000 / myFrameTime).toFixed(1)} FPS)`);
                    }
                }
            });
            
            if (myInitialPredictionStartTime === 0) {
                await tf.backend().queue.onSubmittedWorkDone();
            }
            
            myFrameCount++;
            requestAnimationFrame(myPredict);
        }

        // --- Event Handlers ---
        async function myCameraChangeHandler() {
            if (myIsPredicting) {
                myStopPredictionAndReset();
            }
            await myEnableWebcam(myCameraSelect.value);
        }

        function myModelChangeHandler() {
            myStopPredictionAndReset();
            const mySelectedOption = myModelSelect.options[myModelSelect.selectedIndex];
            myModelUrlInput.value = mySelectedOption.value;
            console.log('üìù Model changed to:', mySelectedOption.text);
            myPreLoadModelMetadata(); 
        }
        
        function myModelUrlInputHandler() {
            myStopPredictionAndReset();
            myPreLoadModelMetadata();
        }

        // --- Initialization and Event Listeners ---
        myLoadButton.onclick = myLoadModel;
        myResetButton.onclick = myFullReset; 
        myCameraSelect.onchange = myCameraChangeHandler;
        myModelSelect.onchange = myModelChangeHandler; 
        myModelUrlInput.onchange = myModelUrlInputHandler; 

        console.log('üé¨ Application initialized');
        myInitializeLiteRT(); 
        myPopulateModelSelect(); 
        myGetCameras();
        myEnableWebcam();
    </script>
</head>
<body style="margin:0; padding:0; height:100vh; display:flex; flex-direction:column; align-items:center; justify-content:center; background-color:#000;">
    <div id="controls" style="position:relative; z-index:2; margin-bottom:10px; padding:5px; background:rgba(255, 255, 255, 0.9); display:flex; flex-direction:column; gap:5px; align-items:center; justify-content:center; max-width: 90vw; border-radius: 8px;">
        <div style="display:flex; flex-wrap:wrap; gap:10px; align-items:center; justify-content:center;">
            <div>
                <label for="cameraSelect">Camera:</label>
                <select id="cameraSelect">
                    <option value="">Loading Cameras...</option>
                </select>
            </div>
            
            <div>
                <label for="modelSelect">Model Preset:</label>
                <select id="modelSelect">
                    </select>
            </div>
        </div>
        
        <div style="width: 100%; display: flex; flex-direction: column; align-items: center; gap: 5px;">
            <label for="myModelUrlInput" style="font-weight: bold;">Custom Model URL (Change to Load Metadata):</label>
            <input type="text" id="myModelUrlInput" style="width: 95%; padding: 5px; border: 1px solid #ccc;" placeholder="Paste .tflite or .json URL here"/>
        </div>

        <div style="display:flex; gap:10px;">
            <button id="loadModelButton" style="padding: 10px 20px; font-weight: bold;">Load Model & Start</button>
            <button id="myResetButton" style="padding: 10px 20px; font-weight: bold; background-color: #ffcccc;">Reset All</button>
        </div>
        
        <hr style="width: 100%; border: 0; border-top: 1px solid #ccc; margin: 5px 0;">

        <div style="display:flex; flex-wrap:wrap; gap:10px; font-size:12px; justify-content:center;">
            <span>Input Size: **<span id="myInputShapeStatus">N/A</span>**</span>
            <span>Input DType: **<span id="myInputDtypeStatus">N/A</span>**</span>
            <span>Output Shape: **<span id="myOutputDetailsStatus">N/A</span>**</span>
            <span>Load Time: **<span id="myLoadStatus">Ready</span>**</span>
            <span>Analysis Delay/FPS: **<span id="myAnalysisStatus">N/A</span>**</span>
        </div>
        
        <div style="background: #ffffcc; padding: 10px; border-radius: 5px; margin-top: 5px; text-align: center;">
            <strong>üìä Debug Mode Active</strong><br>
            <small>Open browser console (F12) to see detailed logging every 30 frames</small>
        </div>
    </div>

    <div style="position:relative; width:640px; height:480px; border: 1px solid white; overflow:hidden;">
        <video id="webcam" autoplay playsinline style="position:absolute; width:100%; height:100%; object-fit:cover; z-index:0;"></video>
        <canvas id="output" style="position:absolute; width:100%; height:100%; z-index:0;"></canvas> 
        <canvas id="overlay" style="position:absolute; top:0; left:0; width:100%; height:100%; pointer-events:none; z-index:1; opacity:0.5;"></canvas>
    </div>
    
    <section id="demos" style="display:none;">
        <h1>LiteRT.js Model Debug Logger</h1>
        <p>This demo logs comprehensive debugging information for TFLite models.</p>
    </section>
</body>
</html>
